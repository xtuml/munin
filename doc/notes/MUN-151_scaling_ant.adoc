= Munin Preliminary Scaling

xtUML Project Analysis Note

== 1 Abstract

This note identifies potential for concurrency and points of data access
contention in the Protocol Verifier.  Alternatives are analysed for
scaling the application to higher throughput.  A path forward is proposed.

== 2 Introduction and Background

In Munin Phase 1 the scalability of the Protocol Verifier application is
explored.  The purpose of the exploration is to prove that the application
can be scaled to production volumes of data throughput in Munin Phase 2.

At the end of Phase 1 Stage 3 of development, the Protocol Verifier is
composed of three interacting domains operating much like a serial pipe.
AEReception receives the audit event data and passes it to AEOrdering.
AEOrdering sequences the audit events and passes them to Sequence
Verification which enforces rules of topology and constraints.

== 3 Requirements

=== 3.1 Throughput as Audit Events per Unit Time

The primary performance requirement is the ability to process many audit
events per unit time.  These audit events will be associated with multiple
concurrent jobs.

=== 3.2 Minimise Performance-Impacting Contention

The Protocol Verifier must enforce constraints that span jobs.
Constraints that require persistence of elements must operate across
multiple jobs separated by time and CPU process.  This is not a new
requirement, but it is a new challenge based on JobID reuse detection and
support of long duration usage of invariants.  These requirements span
shutdown/restart cycles.

.Stream Splitting, JobID Store, Invariant Store
image::scaling.png[Stream Splitting, JobID Store, Invariant Store]

NOTE:  Proposal is that JobID Store is accessed from SVDC.

== 4 Analysis

=== 4.1 General Nature of the Workflow

Any particular _Job_ is largely a sequential process.  Opportunities for
concurrency within a job are minimal and more challenging to leverage.
However, a single job is a relatively small task and can run mostly
independently of other jobs.

The primary opportunity for concurrency is to support the processing of
multiple concurrent jobs.

=== 4.2 Workflow Partitioning by Job

Audit events arriving at the Protocol Verifier may be partitioned into
separate streams.  Let us call this process 'stream splitting'.  A single
stream of audit events may by split into several separate streams of audit
events.  It is critical that all audit events for any single job are split
into the same stream.

As a simple example, consider splitting a stream of audit events into two
separate streams based upon the value of the JobID.  All audit events
carrying JobIDs with an _even_ value are output into one stream; all audit
events carrying JobIDs with an _odd_ value are output into another stream.
This would result in two streams which could be processed by two largely
independent Protocol Verifier instances.  This same process could be used
to split an incoming stream of audit events into an arbitrary number of
separate streams.

The number of split audit event streams shall be configurable.

This is the primary strategy for partitioning the processing and leverages
the <<4.1 General Nature of the Workflow>>.

==== 4.2.1 Audit Event Stream Splitting

Audit events arrive from the monitored system into a single incoming
filesystem directory called (say) 'pvincoming'.  Instances of AEReception
read these files, validate their format against a schema and write to N
separate output folders named (say) 'pvevents<n>' using the splitting
strategy described above.  Inside the 'pvevents<n>' directory, the
splitter writes files named uniquely within the context of the given
folder.  The quantity of events written to a particular file is
configurable as is the amount of time any file is kept open.  These
configuration values tune the size and frequency of the data arriving to
each instance of the Protocol Verifier back end (AEOrdering + Sequence
Verification).

Each 'pvevents<n>' folder serves as the incoming events directory for an
instance of AEOrdering + Sequence Verification.

=== 4.3 Persistence and Contention

Two requirements which imply persistence and contention are identified.
Firstly, the Protocol Verifier must detect the reuse of a JobID.  To
accomplish this, JobIDs must be persisted and queried during the
processing of future jobs.  Secondly, the Protocol Verifier must enforce
constraints involving __extra-job invariants__, values carried in one job
that must match values carried in other jobs.  This also implies that
these values are persisted so that they may be queried later in time and
across separately split streams of audit events.

==== 4.3.1 JobID Store and Invariant Store

Two persistent stores are needed to maintain JobIDs and invariants across
time and concurrent processing.  A simple filesystem-based approach is
likely sufficient using techniques to minimise contention.  However, other
persistence mechanisms may be explored.

==== 4.3.2 Contention Management

The JobID and invariant stores must serialise access to data contained
within them.  Contention shall be minimised by splitting the values
across multiple files, thus dividing the probability of one process having
to wait on another by the number of files used to store the JobID or
invariant.

The JobID store will use a technique similar to that used to split the
audit event stream.  The JobID store will persist JobIDs into files based
upon the value of the JobID.  As a starting point, the number of JobID
files will be based upon the number of split audit event streams as
described in <<4.2 Workflow Partitioning by Job>>.  This value will be
configurable.

==== 4.3.3 Reading and Writing Persistent Stores

===== 4.3.3.1 Reading and Writing the JobID Store

The JobID store is a filesystem directory named 'pvjobids' containing N1
(configured) files holding JobIDs.  A JobID file is named with a number.
It contains only JobID (sets of) strings, one (set) per line.

When Sequence Verification detects the completion of a job (successful or
unsuccessful), it queries the appropriate JobID file.  If the JobID does
not exist, it appends it.  If the JobID does exist, a JobID reuse error is
reported.

Alternatively, the JobID file could be queried earlier in the processing
of the job.  This query could even be done upstream in AEOrdering or
AEReception.  Earlier queries have the advantage of detecting reuse
sooner.  However, earlier queries may require multiple accesses to the
JobID file.  An end-of-job access minimises contention in the JobID store.

===== 4.3.3.2 Reading and Writing the Invariant Store

The invariant store is a filesystem directory named (say) 'pvinvariants'.
An invariant file is named by the invariant value and contains the
invariant label and other properties.  Alternatively, these could be
grouped by "least significant digit" and contain several in a single file.
It is yet to be determined how many invariants will be seen by a running
Protocol Verifier.

When Sequence Verification detects the definition of an invariant, it
writes the properties into the invariant file.

When Sequence Verification detects the usage of an extra-job invariant and
does not find it in its own cache, it queries the appropriate invariant
file.  If it finds it, it caches it.  If it does not it reports an error.

=== 4.4 Assumptions

==== 4.4.1 JobID Uniqueness and Randomness

Each job is identified with a `JobID`.  At this stage of the work, an
assumption is made that JobIDs are unique between different jobs.  And, in
fact, it is an error to see the same JobID on more than one job.

It is also assumed that JobIDs have relatively random values (UUIDs) or
that they are monotonic in nature.

It is noted that there may be a requirement in the future to deal with
"sets" of JobIDs and "correlation IDs".

=== 4.5 Notes

. As noted above, the dependence on form and multiplicity of JobID may be
  endangering this design to be brittle.
. Some research and analysis should be done to understand the impact of
  audit event stream splitting and persistent store partitioning.  How many
  streams it too many?  How many files in a folder is too many?


== 5 Work Required

=== 5.1 Separate AEReception from AEOrdering and Sequence Verification

. Build AEReception to run independently (in a process by itself) of
  AEOrdering + Sequence Verification.
. Change the interface between AEReception and AEOrdering to be file
  based.
. Update the integration build process.
. Do this step first and test an integration build.

=== 5.3 Enhance AEReception to Perform Audit Event Stream Splitting

. Add support for a configurable number of output audit event streams
  including the capability to write files based on number of audit events
  and/or duration of time.
. Isolate the algorithm used to split the event streams, so that
  alternative algorithms can be easily implemented in the future.

=== 5.3 JobID Store

Update Sequence Verifier to write and read a JobID store.  Use an approach
that insulates the application from the underlying persistence mechanism.

=== 5.4 Invariant Store

Update Sequence Verifier to write and read an invariant store.  Use an
approach that insulates the application from the underlying persistence
mechanism.

== 6 Acceptance Test

=== 6.1 Throughput

. Using the AESimulator, produce a known volume of audit events large
  enough to require at least 5 minutes of processing time.
. Configured as a single instance, run and time the Protocol Verifier and
  calculate the throughput.
. Configured as concurrent instances, run and time the Protocol Verifier
  and calculate the throughput.

== 7 Document References

. [[dr-1]] https://onefact.atlassian.net/browse/MUN-151[Draft scaling plan.]

