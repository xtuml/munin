= Enhance Logging with `log4cplus`

xtUML Project Analysis Note

== 1 Abstract

This note outlines enhancements to the practice of logging in the Munin
Protocol Verifier application.

== 2 Introduction and Background

Until January 2024, the MASL C{plus}{plus} model compiler <<dr-2>> used POCO
<<dr-3>> as the underlying logging technology.  Now MASL uses
`log4cplus` <<dr-4>>.  `log4cplus` provides more functionality and is
consistent with `log4j`, which is a popular logging framework for Java.

During testing of the Protocol Verifier, it was noted that the POCO logger
was using more memory than expected.  This was the trigger to change
logging technologies.

`log4cplus` is a bit different.  It makes sense to revisit the logging
strategy employed by the Munin project in the Protocol Verifier.  This
note will outline a Way Forward.

The primary requirements for what to log come from the requirements for
reporting which are documented in <<dr-5>>.  It is noted that logging and
reporting are closely related.  If requirements change for reporting, it
is helpful if a configuration change to the logging can supply the needed
extra reporting information.  And the mechanics for delivering reporting
information and for delivering logging information can be common.

=== 2.1 `log4cplus` Features

There are at least two features in `log4cplus` that make a difference in
Protocol Verifier usage, Logger Hierarchy and 'appender' configuration.

==== 2.1.1 Logger Hierarchy

`log4cplus` (and `log4j`) support logger hierarchy.  A root logger is
defined.  All loggers inherit from the root logger.  Additional subtype
loggers can be defined which, by default, inherit the properties of the
parent.  This allows for fine grained logger definition while keeping
production configuration tractable.

==== 2.1.2 Appender Designation

`log4cplus` supports various 'appenders'.  These are destinations for log
messages.  The most common destination for a log message is a file.
Another type of appender directs log entries to `syslogd`.  There is
support for appending to a Kafka topic.  This is useful in the Protocol
Verifier.  For example, Logger entries bound for Reporting can be assigned
to topics.  Likewise, benchmarking can be enabled, disabled and destined
in this way.

=== 2.2 Logging Best Practices

As preparation for enhancing logging, a few published "Best Practice"
guides were studied.  We will take the opportunity in Munin to adopt/apply
some of these practices while changing to the `log4*` idiom of logging.

==== 2.2.1 Mission Statement

The first Best Practice to logging is to author a mission statement for
the logging and proceed from there.  This aligns with Shlaer-Mellor
domain modelling quite nicely.

==== 2.2.2 Canonical Logging

Canonical logging is the practice of strategically delivering log lines in
a manner that eases the analysis of the logged data.  The technique
accumulates multiple related key-value pairs and logs them together in a
single entry.  An example canonical log message in the Protocol Verifier
will be the 'job failed' log message.  This will be an assembly of all of
the information needed to understand the failure including a trace of the
events composing the failed job.

== 3 Requirements

. Establish a Project Munin logging mission statement to guide decision
  making.
. Design Reporting to flow from Logging.
  ** Reporting shall be mechanically identical to Logging.
  ** Reporting shall be a subset of Logging.
  ** Reporting shall be a configured set of loggers and log levels.
. Support logging levels:
  ** Fatal
  ** Error
  ** Warning
  ** Information
  ** Debug
  ** Trace
. Support conditional log message string arithmetic.
. Establish conventions for enabled logging.
. Define and support a logger hierarchy.
. Establish naming conventions for logger hierarchy.
. Establish rules and guidelines for the construction of log messages.
. Facilitate machine parsing of log messages (using structured logging).
  This will result in logs that can easily be ingested by log analysis
  tooling.
. Identify tooling that will be used to harvest the log data.
. Protect privacy and security by logging application-level information
  judiciously.

== 4 Analysis

=== 4.1 Munin Logging Mission Statement

* Munin software shall log information critical to the verification of protocols.
  This includes detection of alarms, failures and successes.
* Munin software shall be instrumented to enable the measurement of the
  performance of the Protocol Verifier application itself (benchmarking).
* Munin software shall be instrumented sparingly with debug statements
  adequate for defect isolation (debugging).
* The volume of production-level logging shall not exceed the volume of
  production audit event traffic.

=== 4.2 Breakdown of Application Traffic

The Protocol Verifier monitors devices through telemetry.  There are two
levels of detail in this telemetry, that of a _job_ and that of an
_event_.  In general, the user is interested in monitoring the status of a
job.  Events are interesting only when they are erroneous.  Summaries of
aggregated events are interesting in terms of throughput.

=== 4.3 Job Logging

The primary deliverable log entry is the final status of a job.  A job
completes with status _successful_, _failed_ or _alarm_.  Together with
the job type (name) and identifier, this is the key status provided by the
Protocol Verifier.  Failed and alarmed jobs must also report internal
state satisfactory to understanding failure modes in application-level
jobs in the system being monitored.  Canonical logging practices shall be
applied to facilitate problem determination for failed and alarmed jobs.

To provide canonical log messages once and only once per job, information
about the job and events will be accumulated in instance attributes of the
modelled artefacts.  At the end of the job, the accumulated information
will be structured and delivered to the logger.

==== 4.3.1 Job-Level Statistics for Successful Jobs

For successful jobs, the following shall be reported:

* job type (name)
* job identifier
* event count

This job status report shall be logged exactly once at completion of the
job.  This information shall be contained in a single structured log
message.

The recommended location of this logging is in Sequence Verification.

==== 4.3.2 Job-Level Statistics for Failures and Alarms

For failed and alarmed jobs, the following statistics are required:

* job type (name)
* job identifier
* event count
* failure/alarm mode
* event trace
  ** event type (name)
  ** event identifier
  ** ordering (e.g. previous event Ids)

=== 4.4 Audit Event Logging

Logging at the event level is largely infeasible and unnecessary in
production configurations.  However, in anticipation of performance
benchmarking, some event-level statistics shall be gathered in summary
format.

==== 4.4.1 Audit Event Statistics

The primary statistics surrounding audit events are focused around timing.
A logger specifically used for benchmarking shall be defined.  This
benchmarking logger will log an entry at event arrival and another when
the event is processed by Sequence Verification.

=== 4.5 Protocol Verifier Statistics

Several parameters are useful in the maintenance and support of the
Protocol Verifier (itself, as opposed to the application the PV is
monitoring).

The following statistics are reported as they happen.

* worker registered
* worker deregistered
* unassigned job count exceeded
  ** unassigned job count exceeded is reported once upon occurrence and
     then only reported again if the unassigned job count goes below the
     threshold.

The following statistics are reported periodically.

* event count since start
* event throughput
* worker count
* concurrent jobs at each worker
* concurrent jobs overall (Assigned Jobs)
* unassigned jobs
* unassigned job count exceeded

This information shall be reported on a regular basis not exceeding once
per second (1 Hertz).  The timing shall be configurable.

The recommended location of this logging is in Job Management.

=== 4.6 Logger Hierarchy

As described above, `log4cplus` supports a logger hierarchy.  This
provides a dimension of configuration that can be quite helpful.  For
example, if we define loggers at the class-level, by default they can be
left unconfigured and simply inherit the configuration of the domain
logger.  And then when selective and isolated debugging is needed
(especially in a production environment), it can be accomplished class by
class.

* The top-level logger shall be 'pv' (Protocol Verifier).
* Each domain shall have a logger.
  ** 'pv.jm':  Job Management
  ** 'pv.aeo':  Audit Event Ordering
  ** 'pv.sv':  Sequence Verification
  ** 'pv.istore':  Invariant Store
  ** 'pv.vg':  Verification Gateway
     *** 'pv.vg.audit' will be the logger channel used to report PVprime
          audit events.
* Domain-level debug loggers shall append the class name or keyletters to
  the domain-level logger designation.  Most of the Logger entries for
  domain logging will be at the DEBUG level.  However, INFO or WARN level
  logging from these domain level loggers will go to the Reporting back
  end.
  ** 'pv.sv.happyjob' (or 'pv.sv.job') INFO to declare job success, WARN
     to declare job failure or alarm, DEBUG for engineering
     instrumentation.
  ** 'pv.sv.unhappyjob' ditto
* A special logger shall be defined for benchmarking.
  ** 'pv.benchmark':  throughput benchmark (likely used at event reception
  in Job Management and at event processed in Sequence Verification.

=== 4.7 Log Level Meanings

It is important that the log levels are used consistently throughout the
application.

. Log level meanings for Munin:
  ** *Fatal* is used when the PV is about to crash or shut itself down.
  ** *Error* is used when an error (e.g. cannot happen) happens.  (This is
     an error in the PV, not an error detected in the observed system.)
  ** *Warning* is used for job failures and alarms.  This goes to Reporting.
  ** *Information* is used for everything else that goes to Reporting.
  ** *Debug* is used for engineering diagnostics.
  ** *Trace* is not used.

=== 4.8 Log Format

There are two competing formats for log messages:  `LogFmt` and `JSON`.

* LogFmt is simpler and cleaner looking in the source code.
* JSON supports lists/arrays better.
* LogFmt can be converted to JSON.

In our source code, we will follow the LogFmt convention.  In our log
formatter, we will convert to JSON.  Which can then be fed into Open
Telemetry and just about any other log processing system.

Read about LogFmt <<dr-6, here>>.

== 5 Work Required

. Remove the reporting terminator and use loggers for reporting.
. Remove calls to AsyncLogger and use Logger with the new logger hierarchy.
. Log a benchmark for each event as seen in Job Management and again in
  Sequence Verification (tail end).
. Update the source code in the domains to conditionalise log message
  string arithmetic using `Logger::enabled`.
. Update the source code in the domains to log canonically where
  appropriate (svdc_job_failed).
. Update the source code in the domains to avoid logging inside loops and
  other high traffic areas.
. Update the source code in the domains to adhere to the logger hierarchy
  and categories.
. Update the source code in the domains to use structured logging
  according to the prescribed conventions.
. Correctly use the logging levels.  'Error' is not for reporting
  job_failed; it is for reporting errors in the application.

=== 5.1 Project Plan

. Benchmark existing configuration.
  .. Benchmark on Linux EC2.  Attempt to determine maximum throughput.
  .. Document concurrent jobs observed.
  .. Document CPU usage.
  .. Measure the amount of log information created in the various files
     and topics (in bytes per unit time).
. Configure new loggers.
  .. In the logger configureation file, configure the new loggers keeping
     the old loggers.
  .. Observe unchanged behaviour.
. Use new loggers.
  .. Replace calls to Reporting{tilde}>reportEvent() with INFO and WARN
     loggers using the new logger hierarchy.
  .. Replace existing usage of the BenchmarkProbe with a new Logger.
  .. Simply replace the domain logger parameters with the new hierachical
     logger names.
  .. Observe unchanged behaviour.
. Conditionalise logging and log message arithmetic (using Logger::enabled).
. Turn benchmarking on and off.
. Turn debugging on and off.
. Benchmark updated application
  .. Benchmark on Linux EC2.  Try to determine maximum throughput.
  .. Measure the amount of log information created in the various files
     and topics (in bytes per unit time).
. Implement canonical logging for job failures and alarms.
. Implement structured logging.
  .. Define keys for key-value pairs and document them.
  .. Update the log messages to use structured logging employing the
     key-value pairs.
  .. Document the keys used to log.
. Deprecate and remove the Reporting terminator.
. Deprecate and remove the BenchmarkingProbe domain.
. Deprecate and remove the AsyncLogger domain.

== 6 Acceptance Test

. Pass `regression.sh`.
. Run `run_benchmark.sh` and get as good or better performance.

=== 6.1 Data Volume Measurement

. `run_benchmark.sh` on old branch.  Measure the log data per unit time produced.
. `run_benchmark.sh` on new branch.  Measure the log data per unit time produced.
. Ensure that we are logging less data.  If not, understand why.

=== 6.2 Log Analysis

. Run the Protocol Verifier.
. Collect logs.
. Parse them and validate that each field is detectable.

=== 6.3 Consider Concurrency

. Run the PV with debug logs turned on for shared files.
. Run multiple worker PVs.
. Try to clobber files.

== 7 Document References

. [[dr-1]] https://github.com/xtuml/munin/issues/188[188 - Enhance Logging]
. [[dr-2]] https://github.com/xtuml/masl[MASL C{plus}{plus} Model Compiler GitHub Repository]
. [[dr-3]] https://pocoproject.org/[POCO Project]
. [[dr-4]] https://github.com/log4cplus/log4cplus[log4cplus]
. [[dr-5]] link:./189_reporting_ant.adoc[Enhance Reporting Analysis Note]
. [[dr-6]] https://betterstack.com/community/guides/logging/logfmt/[Introduction to LogFmt]

---

This work is licensed under the Creative Commons CC0 License

---
